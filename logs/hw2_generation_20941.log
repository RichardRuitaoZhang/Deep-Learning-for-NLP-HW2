/var/spool/slurmd/job20941/slurm_script: line 17: conda: command not found
/var/spool/slurmd/job20941/slurm_script: line 18: conda: command not found
Starting generative fine-tuning on GPU...
Thu Nov  6 16:14:24 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.86.15              Driver Version: 570.86.15      CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100 80GB PCIe          On  |   00000000:B1:00.0 Off |                    0 |
| N/A   24C    P0             42W /  300W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
loading pretrained weights...
Traceback (most recent call last):
  File "/gpfs/projects/b1080/rz/cs461/HW2/generation.py", line 157, in <module>
    main()
  File "/gpfs/projects/b1080/rz/cs461/HW2/generation.py", line 131, in main
    model = get_modelGPT(opt, vocab_size)
  File "/gpfs/projects/b1080/rz/cs461/HW2/starter.py", line 280, in get_modelGPT
    model.load_state_dict(torch.load(opt.loadname + '/model_weights'))
  File "/home/mnr4714/miniconda3/envs/transformer/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2624, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for TransformerGPT:
	Unexpected key(s) in state_dict: "decoder.layers.6.norm_1.alpha", "decoder.layers.6.norm_1.bias", "decoder.layers.6.norm_2.alpha", "decoder.layers.6.norm_2.bias", "decoder.layers.6.attn_1.q_linear.weight", "decoder.layers.6.attn_1.q_linear.bias", "decoder.layers.6.attn_1.v_linear.weight", "decoder.layers.6.attn_1.v_linear.bias", "decoder.layers.6.attn_1.k_linear.weight", "decoder.layers.6.attn_1.k_linear.bias", "decoder.layers.6.attn_1.out.weight", "decoder.layers.6.attn_1.out.bias", "decoder.layers.6.ff.linear_1.weight", "decoder.layers.6.ff.linear_1.bias", "decoder.layers.6.ff.linear_2.weight", "decoder.layers.6.ff.linear_2.bias", "decoder.layers.7.norm_1.alpha", "decoder.layers.7.norm_1.bias", "decoder.layers.7.norm_2.alpha", "decoder.layers.7.norm_2.bias", "decoder.layers.7.attn_1.q_linear.weight", "decoder.layers.7.attn_1.q_linear.bias", "decoder.layers.7.attn_1.v_linear.weight", "decoder.layers.7.attn_1.v_linear.bias", "decoder.layers.7.attn_1.k_linear.weight", "decoder.layers.7.attn_1.k_linear.bias", "decoder.layers.7.attn_1.out.weight", "decoder.layers.7.attn_1.out.bias", "decoder.layers.7.ff.linear_1.weight", "decoder.layers.7.ff.linear_1.bias", "decoder.layers.7.ff.linear_2.weight", "decoder.layers.7.ff.linear_2.bias", "decoder.layers.8.norm_1.alpha", "decoder.layers.8.norm_1.bias", "decoder.layers.8.norm_2.alpha", "decoder.layers.8.norm_2.bias", "decoder.layers.8.attn_1.q_linear.weight", "decoder.layers.8.attn_1.q_linear.bias", "decoder.layers.8.attn_1.v_linear.weight", "decoder.layers.8.attn_1.v_linear.bias", "decoder.layers.8.attn_1.k_linear.weight", "decoder.layers.8.attn_1.k_linear.bias", "decoder.layers.8.attn_1.out.weight", "decoder.layers.8.attn_1.out.bias", "decoder.layers.8.ff.linear_1.weight", "decoder.layers.8.ff.linear_1.bias", "decoder.layers.8.ff.linear_2.weight", "decoder.layers.8.ff.linear_2.bias", "decoder.layers.9.norm_1.alpha", "decoder.layers.9.norm_1.bias", "decoder.layers.9.norm_2.alpha", "decoder.layers.9.norm_2.bias", "decoder.layers.9.attn_1.q_linear.weight", "decoder.layers.9.attn_1.q_linear.bias", "decoder.layers.9.attn_1.v_linear.weight", "decoder.layers.9.attn_1.v_linear.bias", "decoder.layers.9.attn_1.k_linear.weight", "decoder.layers.9.attn_1.k_linear.bias", "decoder.layers.9.attn_1.out.weight", "decoder.layers.9.attn_1.out.bias", "decoder.layers.9.ff.linear_1.weight", "decoder.layers.9.ff.linear_1.bias", "decoder.layers.9.ff.linear_2.weight", "decoder.layers.9.ff.linear_2.bias", "decoder.layers.10.norm_1.alpha", "decoder.layers.10.norm_1.bias", "decoder.layers.10.norm_2.alpha", "decoder.layers.10.norm_2.bias", "decoder.layers.10.attn_1.q_linear.weight", "decoder.layers.10.attn_1.q_linear.bias", "decoder.layers.10.attn_1.v_linear.weight", "decoder.layers.10.attn_1.v_linear.bias", "decoder.layers.10.attn_1.k_linear.weight", "decoder.layers.10.attn_1.k_linear.bias", "decoder.layers.10.attn_1.out.weight", "decoder.layers.10.attn_1.out.bias", "decoder.layers.10.ff.linear_1.weight", "decoder.layers.10.ff.linear_1.bias", "decoder.layers.10.ff.linear_2.weight", "decoder.layers.10.ff.linear_2.bias", "decoder.layers.11.norm_1.alpha", "decoder.layers.11.norm_1.bias", "decoder.layers.11.norm_2.alpha", "decoder.layers.11.norm_2.bias", "decoder.layers.11.attn_1.q_linear.weight", "decoder.layers.11.attn_1.q_linear.bias", "decoder.layers.11.attn_1.v_linear.weight", "decoder.layers.11.attn_1.v_linear.bias", "decoder.layers.11.attn_1.k_linear.weight", "decoder.layers.11.attn_1.k_linear.bias", "decoder.layers.11.attn_1.out.weight", "decoder.layers.11.attn_1.out.bias", "decoder.layers.11.ff.linear_1.weight", "decoder.layers.11.ff.linear_1.bias", "decoder.layers.11.ff.linear_2.weight", "decoder.layers.11.ff.linear_2.bias". 
	size mismatch for decoder.embed.embed.weight: copying a param with shape torch.Size([50257, 768]) from checkpoint, the shape in current model is torch.Size([50257, 512]).
	size mismatch for decoder.pe.pe: copying a param with shape torch.Size([1, 4096, 768]) from checkpoint, the shape in current model is torch.Size([1, 4096, 512]).
	size mismatch for decoder.layers.0.norm_1.alpha: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.0.norm_1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.0.norm_2.alpha: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.0.norm_2.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.0.attn_1.q_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.0.attn_1.q_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.0.attn_1.v_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.0.attn_1.v_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.0.attn_1.k_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.0.attn_1.k_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.0.attn_1.out.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.0.attn_1.out.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.0.ff.linear_1.weight: copying a param with shape torch.Size([2048, 768]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for decoder.layers.0.ff.linear_2.weight: copying a param with shape torch.Size([768, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).
	size mismatch for decoder.layers.0.ff.linear_2.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.1.norm_1.alpha: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.1.norm_1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.1.norm_2.alpha: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.1.norm_2.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.1.attn_1.q_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.1.attn_1.q_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.1.attn_1.v_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.1.attn_1.v_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.1.attn_1.k_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.1.attn_1.k_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.1.attn_1.out.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.1.attn_1.out.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.1.ff.linear_1.weight: copying a param with shape torch.Size([2048, 768]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for decoder.layers.1.ff.linear_2.weight: copying a param with shape torch.Size([768, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).
	size mismatch for decoder.layers.1.ff.linear_2.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.2.norm_1.alpha: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.2.norm_1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.2.norm_2.alpha: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.2.norm_2.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.2.attn_1.q_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.2.attn_1.q_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.2.attn_1.v_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.2.attn_1.v_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.2.attn_1.k_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.2.attn_1.k_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.2.attn_1.out.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.2.attn_1.out.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.2.ff.linear_1.weight: copying a param with shape torch.Size([2048, 768]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for decoder.layers.2.ff.linear_2.weight: copying a param with shape torch.Size([768, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).
	size mismatch for decoder.layers.2.ff.linear_2.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.3.norm_1.alpha: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.3.norm_1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.3.norm_2.alpha: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.3.norm_2.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.3.attn_1.q_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.3.attn_1.q_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.3.attn_1.v_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.3.attn_1.v_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.3.attn_1.k_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.3.attn_1.k_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.3.attn_1.out.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.3.attn_1.out.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.3.ff.linear_1.weight: copying a param with shape torch.Size([2048, 768]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for decoder.layers.3.ff.linear_2.weight: copying a param with shape torch.Size([768, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).
	size mismatch for decoder.layers.3.ff.linear_2.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.4.norm_1.alpha: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.4.norm_1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.4.norm_2.alpha: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.4.norm_2.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.4.attn_1.q_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.4.attn_1.q_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.4.attn_1.v_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.4.attn_1.v_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.4.attn_1.k_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.4.attn_1.k_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.4.attn_1.out.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.4.attn_1.out.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.4.ff.linear_1.weight: copying a param with shape torch.Size([2048, 768]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for decoder.layers.4.ff.linear_2.weight: copying a param with shape torch.Size([768, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).
	size mismatch for decoder.layers.4.ff.linear_2.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.5.norm_1.alpha: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.5.norm_1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.5.norm_2.alpha: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.5.norm_2.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.5.attn_1.q_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.5.attn_1.q_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.5.attn_1.v_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.5.attn_1.v_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.5.attn_1.k_linear.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.5.attn_1.k_linear.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.5.attn_1.out.weight: copying a param with shape torch.Size([768, 768]) from checkpoint, the shape in current model is torch.Size([512, 512]).
	size mismatch for decoder.layers.5.attn_1.out.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.layers.5.ff.linear_1.weight: copying a param with shape torch.Size([2048, 768]) from checkpoint, the shape in current model is torch.Size([2048, 512]).
	size mismatch for decoder.layers.5.ff.linear_2.weight: copying a param with shape torch.Size([768, 2048]) from checkpoint, the shape in current model is torch.Size([512, 2048]).
	size mismatch for decoder.layers.5.ff.linear_2.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.norm.alpha: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for decoder.norm.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([512]).
	size mismatch for out.weight: copying a param with shape torch.Size([50257, 768]) from checkpoint, the shape in current model is torch.Size([50257, 512]).
Fine-tuning completed. Model saved to models/qa_finetuned.pt
